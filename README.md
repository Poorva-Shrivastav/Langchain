#

# 1. create ollama embedding

# 2. Load the webpage

# 3. Call loader.load()

# 4. call RecursiveCharacterTextSplitter for creating a text splitter

# 5. split the loaded docs with this text splitter

# 6. create vector store

# 7. create llm with Groq

# 8. create prompt for chat model

# 9. create chain with llm and promt

# 10. create retriever to read the data context that we get from this vector

# 11. with create_retrieval_chain, retrieve the final doc

Google API key : https://aistudio.google.com/apikey

GROQ API Key : https://console.groq.com/keys
